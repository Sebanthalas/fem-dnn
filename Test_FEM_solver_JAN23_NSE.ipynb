{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+NwsD6lzNkzUPk6RjSzp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebanthalas/fem-dnn/blob/main/Test_FEM_solver_JAN23_NSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wUrYPD44MIJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import dolfin\n",
        "except ImportError:\n",
        "    !wget \"https://fem-on-colab.github.io/releases/fenics-install.sh\" -O \"/tmp/fenics-install.sh\" && bash \"/tmp/fenics-install.sh\"\n",
        "    import dolfin\n",
        "%cd drive/MyDrive/research\n",
        "import platform, sys\n",
        "python_version=platform.python_version()\n",
        "from distutils.version import LooseVersion, StrictVersion\n",
        "import matplotlib.pyplot as plt;\n",
        "from IPython.display import clear_output, display; import time; import dolfin.common.plotting as fenicsplot \n",
        "import time\n",
        "import os, sys, shutil\n",
        "from google.colab import files\n",
        "#!python -m pip install Tasmanian --user\n",
        "!pip install hdf5storage\n",
        "!"
      ],
      "metadata": {
        "id": "Mhg0GKtf6Sn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/research\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "# Other libraries\n",
        "import scipy.io as sio\n",
        "from fenics import *\n",
        "#import Tasmanian\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as la\n",
        "import time, os, argparse, io, shutil, sys, math, socket\n",
        "import scipy.io as sio\n",
        "from dolfin import *\n",
        "import sympy2fenics as sf\n",
        "import random"
      ],
      "metadata": {
        "id": "7P3gznWg6UjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================================\n",
        "# The sympy2fenics.py file is needed to compute in a simple way:\n",
        "# - derivatives\n",
        "# - tensor products\n",
        "# ==============================================================\n",
        "def my_LK_fun(x,z,d):\n",
        "  pi = 3.14159265359\n",
        "  pi_s = pi\n",
        "  L_c = 1.0/8.0\n",
        "  L_p = np.max([1.0, 2.0*L_c])\n",
        "  L_c_s = L_c\n",
        "  L_p_s = L_p\n",
        "  L = L_c/L_p\n",
        "  L_s = L\n",
        "  string = -1.2+sqrt(sqrt( pi_s )*  L_s /2.0)* z[0]\n",
        "  for j in range(2, input_dim):\n",
        "    term = z[j-1]*sqrt(sqrt(pi_s)*L_s )*exp(-pow(np.floor(j/2.0)* pi*L_s,2.0)/8.0)\n",
        "    if j % 2 == 0:\n",
        "      term = term*sin(np.floor(j/2.0)* pi_s*x/L_p_s)\n",
        "    else:\n",
        "      term = term*cos(np.floor(j/2.0)* pi_s*x/L_p_s)\n",
        "    string = string + term\n",
        "  string = np.exp(  string )\n",
        "  return(string) \n",
        "def str2exp(s):\n",
        "    return sf.sympy2exp(sf.str2sympy(s))\n",
        "def coeff_extr(j):\n",
        "    #This exctracts the coefficient of the different spaces\n",
        "    # j is the index of the space:\n",
        "    # j=o the vector space for uh\n",
        "    # j=1 the space for  component of te11\n",
        "    # j=2 the space for  component of te12\n",
        "    # j=3 the space for  component of te21\n",
        "    # j=4 the first  row of sigma\n",
        "    # j=5 the second row of sigma\n",
        "    # j=6 the lagrange multiplier (not uch important)\n",
        "    # For this to work the nature of the space has to be the same\n",
        "    W  = Function(Hh)\n",
        "    #Getting the exact DOF location\n",
        "    DoF_map   = Hh.sub(j).dofmap()\n",
        "    DoF_index = DoF_map.dofs()\n",
        "    AUX1 = W.vector().get_local()    # empty DoF vector \n",
        "    AUX2 = Usol.vector().get_local() # All DoF\n",
        "    AUX1[DoF_index] = AUX2[DoF_index]                # corresponding assignation\n",
        "    W.vector().set_local(AUX1)       # corresponding assignation to empy vector\n",
        "    coeff_vector = np.array(W.vector().get_local()) \n",
        "    return coeff_vector\n",
        "# ==============================================================\n",
        "# Boundary conditions\n",
        "# ==============================================================\n",
        "class MyExpression(UserExpression):\n",
        "  def eval(self, value, x):\n",
        "    if x[1] >= 1- DOLFIN_EPS:#-my_LK_fun(x[0],z,d):\n",
        "      value[0] = 0.0\n",
        "    elif x[1] <= 0.0+ DOLFIN_EPS:#+my_LK_fun(x[0],z,d):\n",
        "      value[0] = 0.0\n",
        "    elif x[0] > 1- DOLFIN_EPS:\n",
        "      value[0] = ( 1.0 - ( abs(abs(x[1]) - 0.5 ))/(0.5)  ) \n",
        "    elif x[0] < 0.0+ DOLFIN_EPS:\n",
        "      value[0] = ( 1.0 - ( abs(abs(x[1]) - 0.5 ))/(0.5)  ) \n",
        "    elif ( (x[0] > 0.0625 - DOLFIN_EPS) and (x[0] < 0.1875 +DOLFIN_EPS) and (x[1] > 0.4375 - DOLFIN_EPS) and (x[1] < 0.5625 + DOLFIN_EPS) ):\n",
        "      value[0] = 0.0   \n",
        "    else:\n",
        "      value[0] = 0.0\n",
        "  def value_shape(self):\n",
        "    return (1,)\n",
        "\n",
        "# ==============================================================\n",
        "# The following gives the informations about the solver. \n",
        "# ==============================================================\n",
        "parameters[\"form_compiler\"][\"representation\"] = \"uflacs\"\n",
        "parameters[\"form_compiler\"][\"cpp_optimize\"] = True\n",
        "parameters[\"form_compiler\"][\"quadrature_degree\"] = 4\n",
        "list_linear_solver_methods()\n",
        "# ==============================================================\n",
        "# Define the parameters for the PDE and SG points\n",
        "# ==============================================================\n",
        "# All parameters\n",
        "default_parameters = {\n",
        "  'trial_': 1,\n",
        "\t'num_train_samples':1, #20\n",
        "\t'num_test_samples': 0, #50\n",
        "  'mesh_op': 2, # choose mesh refiniment, 1,2,3,4. Default=2\n",
        "\t'FE_degree': 1, # Use P1 for 2D or above\n",
        "  'example' : 'other',\n",
        "  'input_dim': 4\n",
        "}\n",
        "params = default_parameters\n",
        "exact_FE_soln = 0\n",
        "using_SG_points =0\n",
        "#random samples\n",
        "_trial = params['trial_']\n",
        "np_seed = _trial\n",
        "np.random.seed(np_seed)\n",
        "\n",
        "\n",
        "#================================================================\n",
        "# Choose the mesh: there is 4  barycentric refininements. \n",
        "#                  - use plot(mesh) to see them.\n",
        "#================================================================\n",
        "nk = params['mesh_op']\n",
        "example = params['example']\n",
        "input_dim = params['input_dim']\n",
        "meshname=\"meshes/obstac%03g.xml\"%nk\n",
        "mesh = Mesh(meshname)\n",
        "nn   = FacetNormal(mesh)\n",
        "#================================================================\n",
        "# only for errors\n",
        "#================================================================\n",
        "hvec = mesh.hmax(); # pick the h_max from the mesh\n",
        "nvec = 0;           # Same number as K\n",
        "#================================================================\n",
        "# The following for is not necessary. I use it when I want to obtain results\n",
        "# for different values of m\n",
        "#================================================================\n",
        "\n",
        "for m in [1]:\n",
        "    All_Train_coeff   = []\n",
        "    All_Train_coeff_p = []\n",
        "    All_Test_coeff    = []\n",
        "    All_Test_coeff_p  = []\n",
        "    _L4unorm= []\n",
        "    _L2tnorm= []\n",
        "    _L2pnorm= []\n",
        "    _L2snorm= []\n",
        "    input_dim = params['input_dim']\n",
        "    Nu = m\n",
        "    d = input_dim       # parametric dimension\n",
        "    y_in_train = 2.0*np.random.rand(d,m) - 1.0  # training points    \n",
        "    Re = Constant(150)\n",
        "    g     = Constant((0.,0.))\n",
        "    f     = Constant((0.0,0.))\n",
        "    cero  = Constant((0.,0.))\n",
        "    upper = Constant((10.,0.))\n",
        "    Id    = Constant(((1.,0.),(0.,1.)))\n",
        "    #y_in_train = (2.0*np.random.rand(d,m) - 1.0)\n",
        "    # Generate the training data\n",
        "    for i in range(m):\n",
        "      coeff_each_m = []\n",
        "      coeff_each_m_p = []\n",
        "      # time\n",
        "      t_start = time.time()\n",
        "      # Paramters\n",
        "      z = y_in_train[:,i]\n",
        "      # ******* Exact solutions for error analysis ****** \n",
        "      #================================================================\n",
        "      # The viscosity of the fluid depends on the parameters\n",
        "      #================================================================\n",
        "      \n",
        "      if example == 'logKL_expansion':\n",
        "         pi = 3.14159265359\n",
        "         pi_s = str(pi)\n",
        "         L_c = 1.0/8.0\n",
        "         L_p = np.max([1.0, 2.0*L_c])\n",
        "         L_c_s = str(L_c)\n",
        "         L_p_s = str(L_p)\n",
        "         L = L_c/L_p\n",
        "         L_s = str(L)      \n",
        "         string = '-4.5+sqrt(sqrt(' + pi_s + ')*' + L_s + '/2.0)*' + str(z[0])\n",
        "         for j in range(2, input_dim):\n",
        "           term = str(z[j-1]) + '*sqrt(sqrt(' + pi_s + ')*' + L_s + ')*exp(-pow(floor('\n",
        "           term = term + str(j) + '/2.0)*' + pi_s + '*' + L_s + ',2.0)/8.0)' \n",
        "           if j % 2 == 0:\n",
        "             term = term + '*sin(floor(' + str(j) + '/2.0)*' + pi_s + '*x/' + L_p_s + ')'\n",
        "           else:\n",
        "             term = term + '*cos(floor(' + str(j) + '/2.0)*' + pi_s + '*x/' + L_p_s + ')'\n",
        "           string = string + '+' + term\n",
        "         string = 'exp(' + string + ')'\n",
        "      else:# use a simple example where only the first two dimensions have x dependence\n",
        "        string = 1/150\n",
        "        #string = '5.0+exp(' + str(z[0]) + '+' + str(z[1]) + '+' + str(z[2]) + '+'+ str(z[3]) +' )' \n",
        "        \n",
        "      #mu = Expression(str2exp(string), degree=2, domain=mesh)\n",
        "      #mu = Constant(string)\n",
        "      mu = Constant(1/0.1)\n",
        "      #================================================================\n",
        "      # Boundary condition\n",
        "      #================================================================ \n",
        "      u_D = MyExpression()\n",
        "      u_str = '(  1.0, 0.0 )'       \n",
        "      u_ex     = Expression(str2exp(u_str), degree=7, domain=mesh)     \n",
        "      \n",
        "    #================================================================\n",
        "    #  *********** Finite Element spaces ************* #\n",
        "    #================================================================\n",
        "      deg= params['FE_degree']\n",
        "      Pkv = VectorElement('DG', mesh.ufl_cell(), deg)\n",
        "      Pk  = FiniteElement('DG', mesh.ufl_cell(), deg)\n",
        "      RTv = FiniteElement('RT', mesh.ufl_cell(), deg+1)\n",
        "      R0  = FiniteElement('R', mesh.ufl_cell(), 0)\n",
        "      Hh  = FunctionSpace(mesh, MixedElement([Pkv,Pk,Pk,Pk,RTv,RTv,R0]))\n",
        "      Ph  = FunctionSpace(mesh,'CG',1)\n",
        "      nvec = Hh.dim()\n",
        "     #================================================================\n",
        "     # *********** Trial and test functions ********** #\n",
        "     #================================================================\n",
        "      Utrial = TrialFunction(Hh)\n",
        "      Usol   = Function(Hh)\n",
        "      W_trainsol   = Function(Hh)\n",
        "      u, t11, t12, t21, Rsig1, Rsig2, xi= split(Usol)\n",
        "      v, s11, s12, s21, Rtau1, Rtau2, ze= TestFunctions(Hh)\n",
        "      t = as_tensor(((t11,t12),(t21,-t11)))\n",
        "      s = as_tensor(((s11,s12),(s21,-s11))) \n",
        "      sigma = as_tensor((Rsig1,Rsig2))\n",
        "      tau   = as_tensor((Rtau1,Rtau2))\n",
        "      # ********** Boundary conditions ******** #\n",
        "      # All Dirichlet BCs become natural in this mixed form \n",
        "      # *************** Variational forms ***************** #\n",
        "      #================================================================\n",
        "      # flow equations\n",
        "      #================================================================   \n",
        "      # Weak formulation  \n",
        "      BigA = - dot(div(sigma),v)*dx + 0.5*dot(t*u,v)*dx\n",
        "      BigB = 2.*mu*inner(sym(t),s)*dx - 0.5*inner(dev(outer(u,u)),s)*dx - inner(dev(sigma),s)*dx \n",
        "      BigC = inner(tau,t)*dx  + dot(u,div(tau))*dx\n",
        "      # right part and boundary equation\n",
        "      F  = dot(g+f,v)*dx\n",
        "      G  = (dot(tau*nn,u_ex*u_D[0]))*ds \n",
        "      # zero average of trace\n",
        "      Z  = (tr(2*sigma+outer(u,u))) * ze * dx + tr(tau) * xi * dx\n",
        "      #Stiffness matrix\n",
        "      FF = BigA + BigB + BigC  - F - G  + Z\n",
        "    \t# solver\t\t\t\t\t\t    \n",
        "      Tang = derivative(FF, Usol, Utrial)\n",
        "      solve(FF == 0, Usol, J=Tang)\n",
        "      #Solutions\n",
        "      uh, t11h, t12h, t21h, Rsigh1, Rsigh2, xih = Usol.split()\n",
        "      th=as_tensor(((t11h,t12h),(t21h,-t11h)))\t\t\t\t\t    \n",
        "      sigmah = as_tensor((Rsigh1,Rsigh2))        \n",
        "      # dimension-dependent (not separating H_0(div) with c*I)\n",
        "      #getting coeffiecients of p\n",
        "      ph = project(-0.25*tr(2*sigmah+outer(uh,uh)),Ph)\n",
        "      coeff_each_m_p = ph.vector().get_local()\n",
        "      All_Train_coeff_p.append(coeff_each_m_p)\n",
        "      #\n",
        "      num_subspaces = W_trainsol.num_sub_spaces()-1\n",
        "      for j in range(num_subspaces):\n",
        "        coef_one_trial = coeff_extr(j)\n",
        "        coeff_each_m.append(coef_one_trial)\n",
        "      All_Train_coeff.append(coeff_each_m)\n",
        "      print('====================================================================')\n",
        "      print('i = ', i, ' ', y_in_train[:,i])\n",
        "      print('====================================================================')\n",
        "      L4unorm  = sqrt(sqrt(assemble( ((uh)**2)**2*dx)))\n",
        "      L2tnorm  = sqrt(assemble( (th)**2*dx ))\n",
        "      L2pnorm  = sqrt(assemble((ph)**2*dx) ) \n",
        "      L2snorm  = sqrt(assemble((sigmah)**2*dx) ) \n",
        "      print(L4unorm,L2tnorm,L2pnorm)\n",
        "      _L4unorm.append(L4unorm)\n",
        "      _L2tnorm.append(L2tnorm)\n",
        "      _L2pnorm.append(L2pnorm)\n",
        "      _L2snorm.append(L2snorm)\n",
        "\n",
        "     \n",
        "      if i == 0:\n",
        "        K = len(All_Train_coeff[0][0])\n",
        "        print('FE degrees of freedom K = ',K)\n",
        "      if exact_FE_soln:\n",
        "        # Compute error in L4 and L2 norms\n",
        "        erroru_L4 = sqrt(sqrt(assemble( ((u_ex-uh)**2)**2*dx)))\n",
        "        errort_L2 = sqrt(assemble((th-t_ex)**2*dx))\n",
        "        errorp_L2 = sqrt(assemble((ph-p_ex)**2*dx)) \n",
        "        errorp_Hdiv4_3 = sqrt(assemble((sigma_ex-sigmah)**2*dx) ) +  pow(  assemble(  ( pow(  ( div(sigma_ex)-div(sigmah)  )**2,2.0/3.0 )**1*dx)  )  , 3.0/4.0 )   \n",
        "        # Compute maximum error at vertices\n",
        "        vertex_values_u_ex= u_ex.compute_vertex_values(mesh)\n",
        "        vertex_values_uh   = uh.compute_vertex_values(mesh)\n",
        "        error_max         = np.max(np.abs(vertex_values_u_ex - vertex_values_uh))\n",
        "        timer =time.time() - t_start\n",
        "        # Print errors\n",
        "        print('i = ', i, ' ', y_in_train[:,i])\n",
        "        print('====================================================================')\n",
        "        print(' h    &   e(u)     &  e(t)   &    e(p)   &    e(si)   &   e_m(u) &   time ')\n",
        "        print('====================================================================')\n",
        "        print('%5.5g     %4.4g    %4.4g    %4.4g      %4.4g       %4.4g     %4.4g  ' % (hvec, erroru_L4, errort_L2, errorp_L2, errorp_Hdiv4_3, error_max,timer ))\n",
        "        print('======================================================================')\n",
        "    print('Generated inputs of size: ', y_in_train.shape)\n",
        "    print('Generated outputs of size: ', coef_one_trial.shape[0])\n",
        "    # generate the test points\n",
        "    if using_SG_points:\n",
        "        # create the sparse grid generator\n",
        "        grid = Tasmanian.SparseGrid()\n",
        "        # specify the level    \n",
        "        level = 4\n",
        "        # generate sparse grid points and weights\n",
        "        grid.makeGlobalGrid(d, 0, level, \"level\", \"clenshaw-curtis\")\n",
        "        # get the points and weights from the generator\n",
        "        y_in_test = np.transpose(grid.getPoints())\n",
        "        w_test_weights = grid.getQuadratureWeights()\n",
        "        m_test = y_in_test.shape[1]\n",
        "        print('Using Clenshaw-Curtis sparse grid points with ', m_test, ' points')\n",
        "        print('Sum of weights = ', np.sum(w_test_weights))\n",
        "        # scatter plot the points\n",
        "        #plt.scatter(y_in_test[0,:], y_in_test[1,:])\n",
        "        #plt.show()\n",
        "\n",
        "    else:\n",
        "        # get the number of test points\n",
        "        m_test = params['num_test_samples']\n",
        "\n",
        "        # generate the points randomly\n",
        "        y_in_test = 2.0*np.random.rand(d,m_test) - 1.0\n",
        "\n",
        "    print('Generating the testing data')\n",
        "    # Generate the training data\n",
        "    for i in range(m_test):\n",
        "      coeff_each_m = []\n",
        "      coeff_each_m_p = []\n",
        "      t_start = time.time()\n",
        "      # get the training data inputs \n",
        "      z = y_in_test[:,i]\n",
        "      #================================================================\n",
        "      # The viscosity of the fluid depends on the parameters\n",
        "      #================================================================\n",
        "      mu = Expression(str2exp(string), degree=2, domain=mesh)\n",
        "      #================================================================\n",
        "      # Exact solutions settings\n",
        "      #================================================================        \n",
        "      u_D = MyExpression()    \n",
        "      u_ex     = Expression(str2exp(u_str), degree=7, domain=mesh)   \n",
        "    #================================================================\n",
        "    #  *********** Finite Element spaces ************* #\n",
        "    #================================================================\n",
        "      Pkv = VectorElement('DG', mesh.ufl_cell(), deg)\n",
        "      Pk  = FiniteElement('DG', mesh.ufl_cell(), deg)\n",
        "      RTv = FiniteElement('RT', mesh.ufl_cell(), deg+1)\n",
        "      R0  = FiniteElement('R', mesh.ufl_cell(), 0)\n",
        "      Hh  = FunctionSpace(mesh, MixedElement([Pkv,Pk,Pk,Pk,RTv,RTv,R0]))\n",
        "      Ph  = FunctionSpace(mesh,'CG',1)\n",
        "      nvec = Hh.dim()\n",
        "     #================================================================\n",
        "     # *********** Trial and test functions ********** #\n",
        "     #================================================================\n",
        "      Utrial = TrialFunction(Hh)\n",
        "      Usol   = Function(Hh)\n",
        "      W_trainsol = Function(Hh)\n",
        "      u, t11, t12, t21, Rsig1, Rsig2, xi= split(Usol)\n",
        "      v, s11, s12, s21, Rtau1, Rtau2, ze= TestFunctions(Hh)\n",
        "      t = as_tensor(((t11,t12),(t21,-t11)))\n",
        "      s = as_tensor(((s11,s12),(s21,-s11))) \n",
        "      sigma = as_tensor((Rsig1,Rsig2))\n",
        "      tau   = as_tensor((Rtau1,Rtau2))\n",
        "      # ********** Boundary conditions ******** #\n",
        "      # All Dirichlet BCs become natural in this mixed form \n",
        "      # *************** Variational forms ***************** #\n",
        "      #================================================================\n",
        "      # flow equations\n",
        "      #================================================================   \n",
        "      # Weak formulation  \n",
        "      BigA = - dot(div(sigma),v)*dx + 0.5*dot(t*u,v)*dx\n",
        "      BigB = 2.*mu*inner(sym(t),s)*dx - 0.5*inner(dev(outer(u,u)),s)*dx - inner(dev(sigma),s)*dx \n",
        "      BigC = inner(tau,t)*dx  + dot(u,div(tau))*dx\n",
        "      # right part and boundary equation\n",
        "      F  = dot(g+f,v)*dx\n",
        "      G  = (dot(tau*nn,u_ex*u_D[0]))*ds\n",
        "      # zero average of trace\n",
        "      Z  = (tr(2*sigma+outer(u,u))) * ze * dx + tr(tau) * xi * dx\n",
        "        \n",
        "      FF = BigA + BigB + BigC  - F - G  + Z\n",
        "    \t\t\t\t\t\t\t    \n",
        "      Tang = derivative(FF, Usol, Utrial)\n",
        "\n",
        "      solve(FF == 0, Usol, J=Tang)\n",
        "\n",
        "      uh, t11h, t12h, t21h, Rsigh1, Rsigh2, xih = Usol.split()\n",
        "      th=as_tensor(((t11h,t12h),(t21h,-t11h)))\t\t\t\t\t    \n",
        "      sigmah = as_tensor((Rsigh1,Rsigh2))        \n",
        "      # dimension-dependent (not separating H_0(div) with c*I)\n",
        "      \n",
        "      ph = project(-0.25*tr(2*sigmah+outer(uh,uh)),Ph)\n",
        "      coeff_each_m_p = ph.vector().get_local()\n",
        "      All_Test_coeff_p.append(coeff_each_m_p)\n",
        "      # Get the evaluations in a testing grid\n",
        "      num_subspaces = W_trainsol.num_sub_spaces()-1\n",
        "      coeff_each_m = Usol.vector().get_local()\n",
        "      All_Test_coeff.append(coeff_each_m)\n",
        "      print('====================================================================')\n",
        "      print('i = ', i, ' ', y_in_test[:,i])\n",
        "      print('====================================================================')\n",
        "\n",
        "      if i == 0:\n",
        "        K = len(All_Train_coeff[0][0])\n",
        "        print('FE degrees of freedom K = ',K)\n",
        "      if exact_FE_soln:\n",
        "        # Compute error in L2 norm\n",
        "        #erroru_L4 = sqrt(sqrt(assemble( ((u_ex-uh)**2)**2*dx)))\n",
        "        #errort_L2 = sqrt(assemble((th-t_ex)**2*dx))\n",
        "        #errorp_L2 = sqrt(assemble((ph-p_ex)**2*dx)) \n",
        "        #errorp_Hdiv4_3 = sqrt(assemble((sigma_ex-sigmah)**2*dx) ) +  pow(  assemble(  ( pow(  ( div(sigma_ex)-div(sigmah)  )**2,2.0/3.0 )**1*dx)  )  , 3.0/4.0 )     \n",
        "        # Compute maximum error at vertices\n",
        "        vertex_values_u_ex= u_ex.compute_vertex_values(mesh)\n",
        "        vertex_values_uh   = uh.compute_vertex_values(mesh)\n",
        "        error_max         = np.max(np.abs(vertex_values_u_ex - vertex_values_uh))\n",
        "        timer =time.time() - t_start\n",
        "        # Print errors\n",
        "        print('i = ', i, ' ', y_in_test[:,i])\n",
        "        print('====================================================================')\n",
        "        print('h    &   e(u)     &  e(t)   &    e(p)   &    e(si)   &   e_m(u) &   time ')\n",
        "        print('====================================================================')\n",
        "        print('%5.5g     %4.4g    %4.4g    %4.4g      %4.4g       %4.4g     %4.4g  ' % (hvec, erroru_L4, errort_L2, errorp_L2, errorp_Hdiv4_3, error_max,timer ))\n",
        "        print('======================================================================')\n",
        "    # Save the training and test#\n",
        "    train_scratchdir = '/content/drive/My Drive/research/TRAIN/DNN_BANACH_NSE_REAL_d'+str(d)+'_trial_'+str(_trial)+'/result_m_'+str(Nu)+''\n",
        "    testn_scratchdir = '/content/drive/My Drive/research/TESTN/DNN_BANACH_NSE_REAL_d'+str(d)+'_trial_'+str(_trial)+'/result_m_'+str(Nu)+''\n",
        "    result_folder  = train_scratchdir + '/results_mesh' +str(nk)+ '_FE_degree_'+ str(deg)+'_no_p'\n",
        "    scratch_folder = testn_scratchdir + '/results_mesh' +str(nk)+ '_FE_degree_'+ str(deg)+'_no_p'\n",
        "    if not os.path.exists(result_folder):\n",
        "        os.makedirs(result_folder)    \n",
        "    if not os.path.exists(scratch_folder): \n",
        "        os.makedirs(scratch_folder)\n",
        "\n",
        "    print('Generated inputs of size: ', y_in_test.shape)\n",
        "    print('Generated outputs of size: ', All_Train_coeff[0][0].shape)\n",
        "\n",
        "    run_data = {}\n",
        "    run_data['d']              = d\n",
        "    run_data['K']              = K\n",
        "    run_data['Nu']             = Nu\n",
        "    run_data['mesh_op']        = nk\n",
        "    run_data['FE_degree']      = deg\n",
        "    run_data['m']              = m\n",
        "    run_data['m_test']         = m_test\n",
        "\n",
        " \n",
        "   #===============================================\n",
        "   # DOF Coeff- for each function separate\n",
        "   #===============================================    \n",
        "\n",
        "    run_data['All_Train_coeff']     = All_Train_coeff\n",
        "    run_data['All_Test_coeff']      = All_Test_coeff\n",
        "    run_data['All_Train_coeff_p']     = All_Train_coeff_p\n",
        "    run_data['All_Test_coeff_p']     = All_Test_coeff_p\n",
        "    run_data['y_in_test_data']      = y_in_test\n",
        "    run_data['y_in_train_data']      = y_in_train\n",
        "    run_data['_L4unorm']      = _L4unorm\n",
        "    run_data['_L2tnorm']      = _L2tnorm\n",
        "    run_data['_L2pnorm']      = _L2pnorm\n",
        "    run_data['_L2snorm']      = _L2snorm\n",
        "    #run_data['w_test_weights']      = w_test_weights\n",
        "\n",
        "    run_data['fenics_mesh_coords']       = np.array(mesh.coordinates())\n",
        "    run_data['fenics_mesh_cells']        = np.array(mesh.cells())\n",
        "    run_data['fenics_mesh_num_cells']    = np.array(mesh.num_cells())\n",
        "    run_data['fenics_mesh_num_edges']    = np.array(mesh.num_edges())\n",
        "    run_data['fenics_mesh_num_vertices'] = np.array(mesh.num_vertices())\n",
        "    run_data['fenics_mesh_hmax']         = np.array(mesh.hmax())\n",
        "    run_data['fenics_mesh_hmin']         = np.array(mesh.hmin())\n",
        "    run_data['fenics_mesh_rmax']         = np.array(mesh.rmax())\n",
        "    run_data['fenics_mesh_rmin']         = np.array(mesh.rmin())\n",
        "    sio.savemat(result_folder + '/run_data_train.mat', run_data)"
      ],
      "metadata": {
        "id": "OFLCw9WU6Wlu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}